{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Extractive summarization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmA0LchL5zpD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7a9c8cc6-16c5-48fd-f9a5-a70feebab07d"
      },
      "source": [
        "'''\n",
        "This notebook (as it is) tests the best extractive model on the validation and test sets\n",
        "In order to train a new model uncomment the line containing the call to the train function (make sure the load variable is set to False)\n",
        "The usage of a GPU is recommended\n",
        "\n",
        "The model is a reimplementation of the paper: https://arxiv.org/pdf/1611.04230.pdf\n",
        "'''"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nThis notebook (as it is) tests the best extractive model on the validation and test sets\\nIn order to train a new model uncomment the line containing the call to the train function (make sure the load variable is set to False)\\nThe usage of a GPU is recommended\\n\\nThe model is a reimplementation of the paper: https://arxiv.org/pdf/1611.04230.pdf\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDaupd8wOIdV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1657f589-aa3f-44c1-c9fa-8e463356228a"
      },
      "source": [
        "# Install packages\n",
        "!pip install -U torchtext\n",
        "!pip install Rouge\n",
        "!pip install datasets"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.62.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Collecting Rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from Rouge) (1.15.0)\n",
            "Installing collected packages: Rouge\n",
            "Successfully installed Rouge-1.0.1\n",
            "Collecting datasets\n",
            "  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n",
            "\u001b[K     |████████████████████████████████| 264 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 38.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<0.1.0\n",
            "  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.0)\n",
            "Collecting fsspec>=2021.05.0\n",
            "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 48.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: xxhash, huggingface-hub, fsspec, datasets\n",
            "Successfully installed datasets-1.11.0 fsspec-2021.7.0 huggingface-hub-0.0.16 xxhash-2.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApotZWXQbQCs"
      },
      "source": [
        "# imports\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "import os, struct\n",
        "import glob\n",
        "import random\n",
        "import csv\n",
        "from tensorflow.core.example import example_pb2\n",
        "import torch, torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from collections import defaultdict\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from rouge import Rouge\n",
        "import gc, math\n",
        "import json\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "torch.set_printoptions(4)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI-KvPFyM2wk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ec1a5b-f130-44c3-9a90-419a3d026e7a"
      },
      "source": [
        "# To train the model with a batch size of 500 15 GB of GPU memory are required\n",
        "from pynvml import *\n",
        "nvmlInit()\n",
        "h = nvmlDeviceGetHandleByIndex(0)\n",
        "info = nvmlDeviceGetMemoryInfo(h)\n",
        "print(f'total    : {info.total/pow(10,9)}')\n",
        "print(f'free     : {info.free/pow(10,9)}')\n",
        "print(f'used     : {info.used/pow(10,9)}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total    : 11.996954624\n",
            "free     : 11.996954624\n",
            "used     : 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av-K9DNku63h"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ijlYbSvAp_m"
      },
      "source": [
        "OOV_WORD, PADDING, START_DEC, STOP_DEC = \"[UNK]\", \"[PAD]\", \"[START]\", \"[STOP]\"\n",
        "''' \n",
        "Vocabulary class\n",
        "The vocabulary is taken from the dataset: \"https://github.com/JafferWilson/Process-Data-of-CNN-DailyMail\" \"FINISHED FILES\"\n",
        "This class encodes the vocabulary in a hot encoding.  \n",
        "'''\n",
        "class Vocab():\n",
        "  def __init__(self, path=\"/content/dataset/cnn_dm_extractive_compressed_5000/vocab\", max_size = None):\n",
        "    self.count = 0\n",
        "    self.word2id = {} # translate a word to its hot encoding\n",
        "    self.id2word = {} # translate an id to word (since this setting is extractive this dictionary is not used)\n",
        "    for w in [OOV_WORD, PADDING, START_DEC, STOP_DEC]:\n",
        "      self.word2id[w] = self.count\n",
        "      self.id2word[self.count] = w\n",
        "      self.count+=1\n",
        "    # populate the vocabulary\n",
        "    with open(path, 'r') as f:\n",
        "      for l in f:\n",
        "        line = l.split()\n",
        "        if(len(line) != 2):\n",
        "          #print(\"Error: wrong voc format (different then 2)\")\n",
        "          pass\n",
        "        else:\n",
        "          if((max_size != None) and (self.get_size()==max_size)): # break if max size is reached\n",
        "            break\n",
        "          self.word2id[line[0]] = self.count\n",
        "          self.id2word[self.count] = line[0]\n",
        "          self.count += 1\n",
        "  \n",
        "  # get id given a word\n",
        "  def get_id(self, word):\n",
        "    if(word not in self.word2id):\n",
        "      return self.word2id[OOV_WORD]\n",
        "    return self.word2id[word]\n",
        "\n",
        "  # get word given the id\n",
        "  def get_word(self, id):\n",
        "    return self.id2word[id]\n",
        "  \n",
        "  # get the size of the vocabulary\n",
        "  def get_size(self):\n",
        "    return len(self.word2id)\n",
        "  \n",
        "  # get word2id dictionary\n",
        "  def get_vocab(self):\n",
        "    return self.word2id"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La8_gNHo7rcz"
      },
      "source": [
        "# MAX_TEXT_LENGTH: 2882\n",
        "# MAX_ABS_LENGTH: 1726\n",
        "# TRUNCATE_TEXT_LENGTH = 580\n",
        "# TRUNCATE_ABSTRACT_LENGTH = 173\n",
        "\n",
        "# Init the maximum number of sentences and tokens per sentence\n",
        "MAX_SENTENCES = 50 # could be set lower\n",
        "TOKEN_PER_SENT = 30"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQLELCUWTRJr"
      },
      "source": [
        "'''\n",
        "The Dataset class\n",
        "This class manages the articles and their respective summaries\n",
        "The dataset loaded is taken from \"https://paperswithcode.com/sota/extractive-document-summarization-on-cnn\"\n",
        "Input:\n",
        "  - mode: the subset to load (train, val or test)\n",
        "  - vocab: the vocabulary class\n",
        "  - max_size: maximum articles to load (None -> All dataset)\n",
        "\n",
        "The class reads and processes the specific subset of the dataset\n",
        "'''\n",
        "class CNN_dailymail(Dataset):\n",
        "  def __init__(self, mode, vocab, max_size = None, path = \"/content/dataset/cnn_dm_extractive_compressed_5000/\"):\n",
        "    if(mode == \"train\"):\n",
        "      self.path = path+\"/train.*\"\n",
        "    elif(mode == \"val\"):\n",
        "      self.path = path+\"/val.*\"\n",
        "    else:\n",
        "      self.path = path+\"/test.*\"\n",
        "\n",
        "    self.tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    self.vocab = vocab\n",
        "    self.examples = {} # The dictionary composed by the samples of the dataset \n",
        "    self.summaries = {} # Contains the strings of the summaries \n",
        "    self.sentences = {} # contains the articles split in sentences\n",
        "    count = 0\n",
        "\n",
        "    files = glob.glob(self.path)\n",
        "    exit = False\n",
        "    for _f in tqdm(files, position=0, leave=True):\n",
        "      with open(_f) as f:\n",
        "        data = json.load(f)\n",
        "        for row in data:\n",
        "          # process the data\n",
        "          no_target, article, summary, str_summary, sentences = self.process(row)\n",
        "          if(not no_target):\n",
        "            self.examples[count] = (article, summary)\n",
        "            self.summaries[count] = str_summary\n",
        "            self.sentences[count] = sentences\n",
        "            count+=1\n",
        "          if((max_size != None) and (count >= max_size)):\n",
        "            exit = True\n",
        "            break\n",
        "      if(exit):\n",
        "        break\n",
        "\n",
        "  # this function process the articles and summaries, it outputs the tensor article and summary, the string summary and the sentences of the article\n",
        "  def process(self, data):\n",
        "    sentences_list = data[\"src\"]\n",
        "    article, sentences = [], []\n",
        "    str_summary = \"\"\n",
        "    \n",
        "    article = [[self.vocab.get_id(\"[PAD]\")]*TOKEN_PER_SENT]*MAX_SENTENCES\n",
        "\n",
        "    for dim1, sentence in enumerate(sentences_list):\n",
        "      sent = \" \".join(sentence)\n",
        "      sentences.append(sent)\n",
        "      sentence = self.tokenizer.tokenize(sent) # remove punctuation\n",
        "      sent_len = 0\n",
        "      # populate the article\n",
        "      if(len(sentences) < MAX_SENTENCES):\n",
        "        for dim2, word in enumerate(sentence):\n",
        "          if(sent_len >= TOKEN_PER_SENT):\n",
        "            break\n",
        "          article[dim1][dim2] = self.vocab.get_id(word)\n",
        "          sent_len += 1\n",
        "\n",
        "    # create the string summary\n",
        "    for idx, target in enumerate(data[\"labels\"]):\n",
        "      if(target == 1):\n",
        "        str_summary += sentences[idx]\n",
        "    \n",
        "    # if the summary is empty, skip this article\n",
        "    if(len(str_summary) == 0):\n",
        "      return True, None, None, None, None\n",
        "    \n",
        "    # add sentences set to 0 to reach MAX_SENTENCES\n",
        "    if(len(data[\"labels\"]) < MAX_SENTENCES):\n",
        "      data[\"labels\"].extend([0 for i in range(MAX_SENTENCES-len(data[\"labels\"]))])\n",
        "    return False, torch.tensor(article), torch.tensor(data[\"labels\"][:MAX_SENTENCES]), str_summary, sentences\n",
        "\n",
        "  # return the (article, summary), the string summary and the sentences (joined with \"|\" since this list can have a different size and the dataloader would get an error)\n",
        "  def __getitem__(self, idx):\n",
        "    return self.examples[idx], self.summaries[idx], \"|\".join(self.sentences[idx])\n",
        "  \n",
        "  # return the size of the dataset\n",
        "  def __len__(self):\n",
        "    return len(self.examples)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALsdQZZM_OF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64be2f54-bb75-43c7-a87a-1112f1369b0e"
      },
      "source": [
        "'''\n",
        "Download the dataset (from my google drive)\n",
        "This will take some seconds\n",
        "'''\n",
        "def download_dataset(drive_id=\"1zcUZtgVpabefM0Q9CEh26HPJFYSpqFmR\", file_name=\"CNN_extractive.zip\"):\n",
        "  path = \"dataset/\" + file_name\n",
        "  os.system(f'mkdir {\"dataset/\"}')\n",
        "  GDRIVE_ID = drive_id # id of file in google drive\n",
        "  gdd.download_file_from_google_drive(file_id=GDRIVE_ID,\n",
        "                                dest_path=f\"dataset/{file_name}\",\n",
        "                                unzip=True)\n",
        "  os.remove(\"dataset/CNN_extractive.zip\")\n",
        "\n",
        "if(not os.path.isdir(\"dataset/\")):\n",
        "      download_dataset()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1zcUZtgVpabefM0Q9CEh26HPJFYSpqFmR into dataset/CNN_extractive.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61H40isPEmjU"
      },
      "source": [
        "'''\n",
        "The Encoder, this model has to encode the input sentence\n",
        "The input sentence is processed via two bidirectional GRU layers, the first one at word level and the second one at sentence level\n",
        "The hidden states from the word level layer are concatenated and used as input to the second GRU layer with the previous sentence hidden state (sentence_hidden_state) as hidden state\n",
        "The output is the sentence embedding and the hidden state from the GRU sentence layer\n",
        "'''\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, emb, hidden_size, sentence_length, n_layer, bidirectional, batch_size, vocab, dropout):\n",
        "    super().__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.sentence_length = sentence_length\n",
        "    self.batch_size = batch_size\n",
        "    self.n_layer = n_layer\n",
        "    self.embedding = nn.Embedding(input_size, emb, padding_idx = vocab.get_id(\"[PAD]\"))\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.bidirectional = 1\n",
        "    if(bidirectional):\n",
        "      self.bidirectional = 2\n",
        "    self.word_layer = nn.GRU(emb, hidden_size, num_layers = n_layer, bidirectional = bidirectional, batch_first = True) # initialize the word level GRU layer\n",
        "    self.sentence_layer = nn.GRU(hidden_size * sentence_length, hidden_size, num_layers = n_layer, bidirectional = bidirectional, batch_first=False, dropout=0.4) # initialize the sentence level GRU layer\n",
        "\n",
        "  def forward(self, sentence, sentence_hidden_state):\n",
        "    # sentence [2, 20]\n",
        "    hidden = torch.zeros(self.bidirectional * self.n_layer, self.batch_size, self.hidden_size).to(device)\n",
        "    concat_hidden = None\n",
        "    # for each word in the sentence\n",
        "    for idx in range(self.sentence_length):\n",
        "      word = sentence[:,idx] # word -> [2]\n",
        "      emb = self.dropout(self.embedding(word)).unsqueeze(1) # [2, 1, 256]\n",
        "      word_enc, hidden = self.word_layer(emb, hidden)\n",
        "      if(concat_hidden == None):\n",
        "        concat_hidden = hidden\n",
        "      else:\n",
        "        concat_hidden = torch.cat((concat_hidden, hidden), 2)\n",
        "\n",
        "    sentence_emb, hidden = self.sentence_layer(concat_hidden, sentence_hidden_state)\n",
        "    return sentence_emb, hidden\n",
        "\n",
        "  # init the hidden layer\n",
        "  def init_layers(self):\n",
        "    return torch.zeros(self.bidirectional * self.n_layer, self.batch_size, self.hidden_size).to(device)\n",
        "\n",
        "'''\n",
        "The decoder takes in input the sentence hidden state from the encoder, the hidden sum (H on the report) and the current summary state\n",
        "The decoder performs a non linear transformation on H generating the representation of the entire article d\n",
        "Then the content, saliency and novelty are computed via linear and bilinear transformations\n",
        "Content + saliency - novelty are the input to the final classifier, the ouput of the decoder is the probability for the specific sentence to be selected or not (two classes)\n",
        "'''\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, output_size, hidden_size, input_size, n_layer, vocab, batch_size, dropout):\n",
        "    super().__init__()\n",
        "    self.device = device\n",
        "    self.batch_size = batch_size\n",
        "    self.representation = nn.Linear(hidden_size*2, hidden_size)\n",
        "    self.sentence_transform = nn.Linear(hidden_size*2, hidden_size*2)\n",
        "    self.content = nn.Linear(hidden_size*2, hidden_size, bias = False)\n",
        "    self.salience = nn.Bilinear(hidden_size*2, hidden_size, hidden_size, bias = False)\n",
        "    self.novelty = nn.Bilinear(hidden_size*2, hidden_size*2, hidden_size, bias = False)\n",
        "    self.classifier = nn.Sequential(nn.Linear(hidden_size, hidden_size), nn.Linear(hidden_size, 2))\n",
        "\n",
        "  def forward(self, sentence_hidden, hidden_sum, current_summary_hidden):\n",
        "    d = torch.tanh(self.representation(hidden_sum))\n",
        "    sentence_hidden = torch.tanh(self.sentence_transform(sentence_hidden))\n",
        "    cont = self.content(sentence_hidden)\n",
        "    salience = self.salience(sentence_hidden, d)\n",
        "    novelty = self.novelty(sentence_hidden, torch.tanh(current_summary_hidden))\n",
        "    # d [3, 256]\n",
        "    # sentence [3, 512]\n",
        "    # current_summary_hidden [3, 512]\n",
        "    # cont [3, 256]\n",
        "    # salience [3, 256]\n",
        "    # novelty [3, 256]\n",
        "    return torch.sigmoid(self.classifier(cont+salience-novelty))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JawVMPlR3q4W"
      },
      "source": [
        "'''\n",
        "Converts the predicted output into a list of sentences (strings)\n",
        "Used to compute the Rouge metric\n",
        "'''\n",
        "def convert_pred(output, sentences, vocab):\n",
        "  pred = []\n",
        "  for idx_sample, sample in enumerate(output):\n",
        "    s = ''\n",
        "    sent = sentences[idx_sample].split(\"|\")\n",
        "    for idx_sentence, sentence in enumerate(sample):\n",
        "      if(idx_sentence >= len(sent)):\n",
        "        break\n",
        "      if(sentence == 1):\n",
        "        s += sent[idx_sentence]\n",
        "    if(len(s) == 0):\n",
        "      s = '[PAD]'\n",
        "    pred.append(s)\n",
        "  return pred\n",
        "\n",
        "'''\n",
        "Decode one article (for debugging purposes)\n",
        "'''\n",
        "def print_art(art, vocab):\n",
        "  article = \"\"\n",
        "  for id in art:\n",
        "    article += vocab.get_word(id.item()) + \" \"\n",
        "  return article\n",
        "\n",
        "'''\n",
        "Decode one output as sentence (for debugging purposes)\n",
        "'''\n",
        "def print_pred(sample, vocab):\n",
        "  s = \"\"\n",
        "  for word in sample:\n",
        "    if(vocab.get_word(word.item()) == STOP_DEC):\n",
        "      break\n",
        "    s += vocab.get_word(word.item()) + \" \"\n",
        "  return s\n",
        "\n",
        "'''\n",
        "Compute the Rouge score given the outputs and abstracts of a batch\n",
        "'''\n",
        "def compute_accuracy(outputs, abstracts, sentences, vocab):\n",
        "  acc = Rouge().get_scores(tuple(convert_pred(outputs, sentences, vocab)), tuple(abstracts), avg=True)\n",
        "  return torch.tensor([acc['rouge-1']['r'], \n",
        "         acc['rouge-1']['p'], \n",
        "         acc['rouge-1']['f'],\n",
        "         acc['rouge-2']['r'],\n",
        "         acc['rouge-2']['p'],\n",
        "         acc['rouge-2']['f'],\n",
        "         acc['rouge-l']['r'],\n",
        "         acc['rouge-l']['p'],\n",
        "         acc['rouge-l']['f']])\n",
        "\n",
        "'''\n",
        "Print the metrics in a readable way\n",
        "'''\n",
        "def print_accuracies(acc):\n",
        "  print(f\"----ACC----\\nRouge-1: recall {acc[0]}, precision {acc[1]}, f1 {acc[2]}\\nRouge-2: recall {acc[3]}, precision {acc[4]}, f1 {acc[5]}\\nRouge-l: recall {acc[6]}, precision {acc[7]}, f1 {acc[8]}\\n\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AstiQfiNRpqM"
      },
      "source": [
        "'''\n",
        "Save the encoder and decoder for continuing training\n",
        "'''\n",
        "def save_model(encoder, decoder, epoch, enc_opt, dec_opt):\n",
        "  torch.save({\n",
        "            'epoch': epoch,\n",
        "            'encoder_state_dict': encoder.state_dict(),\n",
        "            'decoder_state_dict': decoder.state_dict(),\n",
        "            'enc_optimizer_state_dict': enc_opt.state_dict(),\n",
        "            'dec_optimizer_state_dict': dec_opt.state_dict()\n",
        "            }, \"/content/model_extractive.ckp\")\n",
        "\n",
        "'''\n",
        "Load a saved model (the best one in this case)\n",
        "'''\n",
        "def load_model(v_length, emb, hidden_size, n_layers, batch_size, vocab, learning_rate=0.01):\n",
        "  encoder = Encoder(v_length, emb, hidden_size, TOKEN_PER_SENT, n_layers, True, batch_size, vocab, dropout = 0.1).to(device)\n",
        "  decoder = Decoder(v_length, hidden_size, MAX_SENTENCES, n_layers, vocab, batch_size, dropout = 0.1).to(device)\n",
        "\n",
        "  enc_opt = torch.optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "  dec_opt = torch.optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "  checkpoint = torch.load(\"/content/model_extractive_best.ckp\")\n",
        "  encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
        "  enc_opt.load_state_dict(checkpoint['enc_optimizer_state_dict'])\n",
        "\n",
        "  decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
        "  dec_opt.load_state_dict(checkpoint['dec_optimizer_state_dict'])\n",
        "\n",
        "  epoch = checkpoint['epoch']\n",
        "\n",
        "  return encoder, enc_opt, decoder, dec_opt, epoch"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr_y7Gngn-yw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea479ec-ce53-497d-d732-228534dc144c"
      },
      "source": [
        "'''\n",
        "Download the best model\n",
        "'''\n",
        "def download_model(drive_id=\"1aphX8f02Vl7-kJboOXmUylTt3h3kO6b7\", file_name=\"model_extractive_best.zip\"):\n",
        "  gdd.download_file_from_google_drive(file_id=drive_id,\n",
        "                                dest_path=f\"/content/{file_name}\",\n",
        "                                unzip=True)\n",
        "  os.remove(f\"/content/{file_name}\")\n",
        "\n",
        "download_model()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1aphX8f02Vl7-kJboOXmUylTt3h3kO6b7 into /content/model_extractive_best.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw1EdtXt4JM0"
      },
      "source": [
        "'''\n",
        "Train the encoder and decoder\n",
        "This function executes N° epochs to train the model\n",
        "Input:\n",
        "  - encoder: the encoder to train\n",
        "  - decoder: the decoder to train\n",
        "  - enc_opt: the optimizer of the encoder\n",
        "  - dec_opt: the optimizer of the decoder\n",
        "  - loss_fn: loss function \n",
        "  - data_loader: the dataloader managing the dataset\n",
        "  - check_val: a dataloader managing a subset of the validation set (1000 samples), to check every \"print_acc\" times\n",
        "  - vocab: the vocabulary object\n",
        "  - batch_size: the size of each batch\n",
        "  - hidden_size: the size of the hidden layers (equal for both encoder and decoder)\n",
        "  - n_sentences: the number of sentences\n",
        "  - epochs: the number of epochs to perform\n",
        "  - epoch: the epoch where to start (0 or the last epoch if the model was loaded)\n",
        "  - device: gpu or cpu\n",
        "'''\n",
        "import sklearn.metrics as metrics\n",
        "def train(encoder, decoder, enc_opt, dec_opt, loss_fn, data_loader, check_val, vocab, batch_size, hidden_size, n_sentences, epochs, epoch, device = \"cuda\"):\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  print_acc = 10 # print the accuracy every 10 epochs\n",
        "  # Put the models in training mode\n",
        "  encoder.train()\n",
        "  decoder.train()\n",
        "\n",
        "  recall_loss, precision_loss, accuracy_loss = 0, 0, 0\n",
        "\n",
        "  # Epochs\n",
        "  for e in range(epoch, epochs):\n",
        "    print(f\"---------EPOCH {e}---------\")\n",
        "    avg_loss = torch.zeros(1) # Average the loss\n",
        "    c = 0\n",
        "    recall_avg, precision_avg, accuracy_avg = 0, 0, 0\n",
        "    acc_avg = torch.zeros(9) # Contains the accuracies (Rouge)\n",
        "    \n",
        "    # For each batch (data = (article, summary), summaries = raw summaries in strings, sentences = sentences of each article delimited by \"|\")\n",
        "    for data, summaries, sentences in tqdm(data_loader, position=0, leave=True):\n",
        "      precision, recall, accuracy = 0, 0, 0\n",
        "      articles, abstracts = data[0].to(device), data[1].to(device)\n",
        "      sentence_hidden = encoder.init_layers() # init the encoder hidden layer\n",
        "      sum_sentence_hidden_states = torch.zeros(batch_size, hidden_size*2).to(device) # set the initial summation of the sentence hidden states to 0\n",
        "      sentence_hidden_states = torch.zeros(n_sentences, batch_size, hidden_size*2).to(device) # set the sentence hidden states to 0\n",
        "      acc = None\n",
        "      # For each sentence of the article computes the encoding\n",
        "      for i in range(n_sentences):\n",
        "        _, sentence_hidden = encoder(articles[:,i].clone().to(device), sentence_hidden)\n",
        "        sentence_hidden_states[i,:] = sentence_hidden.view(1,batch_size,-1).squeeze(0) # save the sentence hidden state\n",
        "        sum_sentence_hidden_states[:] += sentence_hidden.view(1,batch_size,-1).squeeze(0) # sum over the hidden states\n",
        "\n",
        "      H = sum_sentence_hidden_states[:]/n_sentences # normalize the summation -> H\n",
        "      summary_state = torch.zeros(batch_size, hidden_size*2).to(device) # init the summary state to 0\n",
        "\n",
        "      loss = 0\n",
        "\n",
        "      outputs = torch.zeros(batch_size, n_sentences, dtype = torch.int32).to(device) # init the outputs to 0\n",
        "      \n",
        "      # for each sentence of the article\n",
        "      for step in range(n_sentences):\n",
        "        decoder_output = decoder(sentence_hidden_states[step,:].clone().to(device), H.to(device), summary_state.to(device))\n",
        "        outputs[:,step] = decoder_output.argmax(1).detach() # take the highest predicted class\n",
        "        summary_state += sentence_hidden_states[step,:].clone()*decoder_output[:,1].unsqueeze(1).clone() # update the summary state with the hidden state of the current sentence weighted with the probability of being part of the summary\n",
        "        loss += loss_fn(decoder_output.to(device), abstracts[:,step].clone(), recall_loss, precision_loss) # compute loss\n",
        "\n",
        "      enc_opt.zero_grad()\n",
        "      dec_opt.zero_grad()\n",
        "      loss.backward() # compute backpropagation\n",
        "      # clipping\n",
        "      torch.nn.utils.clip_grad_norm_(filter(lambda p: p.requires_grad, encoder.parameters()), 2.) \n",
        "      torch.nn.utils.clip_grad_norm_(filter(lambda p: p.requires_grad, decoder.parameters()), 2.) \n",
        "      enc_opt.step() # apply backpropagation\n",
        "      dec_opt.step()    \n",
        "\n",
        "      # compute precision, recall and accuracy\n",
        "      for idx in range(batch_size):\n",
        "        precision += metrics.precision_score(abstracts[idx].cpu(), outputs[idx].cpu(), zero_division=True)\n",
        "        recall += metrics.recall_score(abstracts[idx].cpu(), outputs[idx].cpu(), zero_division=True)\n",
        "        accuracy += metrics.accuracy_score(abstracts[idx].cpu(), outputs[idx].cpu())\n",
        "\n",
        "      # update avgs\n",
        "      precision_avg += precision/batch_size\n",
        "      recall_avg += recall/batch_size\n",
        "      accuracy_avg += accuracy/batch_size\n",
        "      # compute the accuracy every \"print_acc\" epochs\n",
        "      if((e+1)%print_acc == 0):\n",
        "        acc = compute_accuracy(outputs, summaries, sentences, vocab)\n",
        "        acc_avg += acc\n",
        "\n",
        "      avg_loss += loss.item()/n_sentences\n",
        "      \n",
        "      c += 1\n",
        "\n",
        "    recall_loss = recall_avg/c\n",
        "    precision_loss = precision_avg/c\n",
        "\n",
        "    if((e+1)%print_acc == 0):\n",
        "      # print some prediction and ground truth\n",
        "      # print(outputs[batch_size-1])\n",
        "      # print(abstracts[batch_size-1])\n",
        "      # print(outputs[batch_size-2])\n",
        "      # print(abstracts[batch_size-2])\n",
        "      # print(outputs[batch_size-10])\n",
        "      # print(abstracts[batch_size-10])\n",
        "      # print the accuracy\n",
        "      print_accuracies(acc_avg/c) \n",
        "      # check current performance on a subest of the validation set\n",
        "      print(\"ACC val subset:\\n\")\n",
        "      test(encoder, decoder, check_val, vocab, batch_size, loss_fn) # compute the accuracy in the subset of the validation set\n",
        "      encoder.train()\n",
        "      decoder.train()\n",
        "    print(\"Precision\", precision_loss)\n",
        "    print(\"Recall\", recall_loss)\n",
        "    print(\"Accuracy\", accuracy_avg/c)\n",
        "    save_model(encoder, decoder, e, enc_opt, dec_opt) # save the current model\n",
        "    print(\"\\nLoss: \", (avg_loss/c).item()) # print loss"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rZbBNlTDcPo"
      },
      "source": [
        "'''\n",
        "This function aims at testing the model, the dataloader should be the validation or test set\n",
        "Input:\n",
        " - encoder: the trained encoder\n",
        " - decoder: the trained decoder\n",
        " - loader: the dataloader where to test the model\n",
        " - vocab: the vocabulary\n",
        " - batch_size: the size of each batch\n",
        " - device: cpu or gpu (cuda)\n",
        "'''\n",
        "def test(encoder, decoder, loader, vocab, batch_size, loss_fn, device = \"cuda\"):\n",
        "  torch.cuda.empty_cache()\n",
        "  # evaluation mode\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    c = 0\n",
        "    acc_avg = torch.zeros(9)\n",
        "    recall_avg, precision_avg, accuracy_avg = 0, 0, 0\n",
        "    for data, summaries, sentences in tqdm(loader, position=0, leave=True): # for each batch\n",
        "      precision, recall, accuracy = 0, 0, 0\n",
        "      articles, abstracts = data[0].to(device), data[1].to(device)\n",
        "\n",
        "      sentence_hidden = encoder.init_layers()\n",
        "\n",
        "      n_sentences = articles.size(1)\n",
        "      target_length = abstracts.size(1)\n",
        "\n",
        "      sum_sentence_hidden_states = torch.zeros(batch_size, encoder.hidden_size*2).to(device)\n",
        "      sentence_hidden_states = torch.zeros(n_sentences, batch_size, encoder.hidden_size*2).to(device)\n",
        "\n",
        "      loss = 0\n",
        "\n",
        "      for i in range(n_sentences):\n",
        "        _, sentence_hidden = encoder(articles[:,i].clone().to(device), sentence_hidden)\n",
        "        sentence_hidden_states[i,:] = sentence_hidden.view(1,batch_size,-1).squeeze(0)\n",
        "        sum_sentence_hidden_states[:] += sentence_hidden.view(1,batch_size,-1).squeeze(0)\n",
        "\n",
        "      d = sum_sentence_hidden_states[:]/n_sentences\n",
        "      summary_state = torch.zeros(batch_size, encoder.hidden_size*2).to(device)\n",
        "\n",
        "      outputs = torch.zeros(batch_size, n_sentences, dtype = torch.int32).to(device)\n",
        "\n",
        "      for step in range(target_length):\n",
        "        decoder_output = decoder(sentence_hidden_states[step,:].clone().to(device), d.to(device), summary_state.to(device))\n",
        "        # outputs[:,step] = torch.where(decoder_output > 0.5, 1, 0).squeeze(1)\n",
        "        outputs[:,step] = decoder_output.argmax(1).detach()\n",
        "        summary_state += sentence_hidden_states[step,:].clone()*decoder_output[:,1].unsqueeze(1).clone() \n",
        "        loss += loss_fn(decoder_output.to(device), abstracts[:,step].clone(), recall/batch_size, precision/batch_size)\n",
        "      \n",
        "      for idx in range(batch_size):\n",
        "        precision_avg += metrics.precision_score(abstracts[idx].cpu(), outputs[idx].cpu(), zero_division=True)\n",
        "        recall_avg += metrics.recall_score(abstracts[idx].cpu(), outputs[idx].cpu(), zero_division=True)\n",
        "        accuracy_avg += metrics.accuracy_score(abstracts[idx].cpu(), outputs[idx].cpu())\n",
        "\n",
        "      precision_avg += precision/batch_size\n",
        "      recall_avg += recall/batch_size\n",
        "      accuracy_avg += accuracy/batch_size\n",
        "\n",
        "      acc_avg += compute_accuracy(outputs, summaries, sentences, vocab)\n",
        "      c+=1\n",
        "\n",
        "    print_accuracies(acc_avg/c) "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WlUVrvohqcu"
      },
      "source": [
        "# Compute the baselines using a random approach\n",
        "# select K random sentences for each article (K = 4)\n",
        "def random_baseline(loader, vocab, batch_size, n_sentences, K = 4):\n",
        "  tot_avg = 0\n",
        "  for i in range(10):\n",
        "    acc_avg = 0\n",
        "    c = 0\n",
        "    for data, summaries, sentences in tqdm(loader, position=0, leave=True):\n",
        "      outputs = torch.zeros(batch_size, n_sentences)\n",
        "      rand = torch.rand(batch_size, n_sentences).topk(K, dim=1)[1]\n",
        "      for idx, sample in enumerate(rand):\n",
        "        for sentence in sample:\n",
        "          outputs[idx, sentence] = 1\n",
        "      acc = compute_accuracy(outputs, summaries, sentences, vocab)\n",
        "      acc_avg += acc\n",
        "      c+=1\n",
        "    print_accuracies(acc_avg/c)\n",
        "    tot_avg+=acc_avg/c\n",
        "  print(\"Rouge score averaged over 10 runs:\")\n",
        "  print_accuracies(tot_avg/10)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdP51ZoVJEqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0284810-89a8-4471-ff48-a289ad2260da"
      },
      "source": [
        "# Init the vocabulary\n",
        "vocab = Vocab(max_size = 50000)\n",
        "\n",
        "# Load the datasets\n",
        "t = CNN_dailymail(\"train\", vocab, max_size=5000)\n",
        "v = CNN_dailymail(\"val\", vocab)\n",
        "check_val = CNN_dailymail(\"val\", vocab, max_size=1000) # to check validation performances during training\n",
        "te = CNN_dailymail(\"test\", vocab)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/58 [00:05<?, ?it/s]\n",
            "100%|██████████| 3/3 [00:11<00:00,  3.93s/it]\n",
            "  0%|          | 0/3 [00:01<?, ?it/s]\n",
            "100%|██████████| 3/3 [00:09<00:00,  3.31s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9zstYd7i_Ra"
      },
      "source": [
        "# init the device to use\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "batch_size = 500 # need to have 15 GB of gpu memory available\n",
        "\n",
        "# init the dataloaders\n",
        "train_ds = DataLoader(t, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
        "val_ds = DataLoader(v, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True, drop_last=True)\n",
        "check_val = DataLoader(check_val, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True, drop_last=True)\n",
        "test_ds = DataLoader(te, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True, drop_last=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvYZFfu-FFo2"
      },
      "source": [
        "# loss function\n",
        "def loss(outputs, targets, recall, precision):\n",
        "  weight_class_0 = 0.1\n",
        "  weight_class_1 = 1.0\n",
        "  return nn.CrossEntropyLoss(weight=torch.tensor([weight_class_0, weight_class_1])).to(device)(outputs, targets) + (1-(recall*precision))**2\n",
        "  # return nn.CrossEntropyLoss(weight=torch.tensor([weight_class_0, weight_class_1])).to(device)(outputs, targets)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyJJoG5PcC-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "776c44c9-0fb4-4608-9682-9ecb69b645c4"
      },
      "source": [
        "v_length = vocab.get_size()\n",
        "emb, hidden_size = 64, 128\n",
        "\n",
        "load = True # load the best model\n",
        "lr = 0.001 # learning rate\n",
        "epoch = 0 # starting epoch\n",
        "force_training = False # start from epoch 0 (if already trained model)\n",
        "n_layers = 1 # number of layers for the GRU units\n",
        "\n",
        "if(not load):\n",
        "  # init the models\n",
        "  encoder = Encoder(v_length, emb, hidden_size, TOKEN_PER_SENT, n_layers, True, batch_size, vocab, dropout = 0.1).to(device)\n",
        "  decoder = Decoder(v_length, hidden_size, MAX_SENTENCES, 1, vocab, batch_size, dropout = 0.1).to(device)\n",
        "  opt_enc = torch.optim.Adam(encoder.parameters(), lr=lr)\n",
        "  opt_dec = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "  # init optimizers\n",
        "  # opt_enc = torch.optim.SGD(encoder.parameters(), lr=lr)\n",
        "  # opt_dec = torch.optim.SGD(decoder.parameters(), lr=lr)\n",
        "else:\n",
        "  # load the last saved models\n",
        "  encoder, opt_enc, decoder, opt_dec, epoch = load_model(vocab.get_size(), emb, hidden_size, n_layers, batch_size, vocab, learning_rate=lr)\n",
        "\n",
        "loss_fn = loss\n",
        "\n",
        "if(force_training):\n",
        "  epoch = 0\n",
        "\n",
        "print(\"\\nN° Parameters: \", (sum(p.numel() for p in encoder.parameters() if p.requires_grad) + sum(p.numel() for p in decoder.parameters() if p.requires_grad)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "N° Parameters:  19129090\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IorOfSzZBlwr"
      },
      "source": [
        "# To train a new model uncomment the below line (make sure the load variable is set to False)\n",
        "# train(encoder, decoder, opt_enc, opt_dec, loss_fn, train_ds, check_val, vocab, batch_size, hidden_size, MAX_SENTENCES, 90, epoch, device)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVu77-AcrWCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec550b5-bfeb-4a65-c156-6744548b3e7a"
      },
      "source": [
        "# Eventually test the final model\n",
        "\n",
        "test(encoder, decoder, val_ds, vocab, batch_size, loss)\n",
        "\n",
        "test(encoder, decoder, test_ds, vocab, batch_size, loss)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 26/26 [03:14<00:00,  7.49s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----ACC----\n",
            "Rouge-1: recall 0.5485537648200989, precision 0.47357696294784546, f1 0.4781179130077362\n",
            "Rouge-2: recall 0.40462473034858704, precision 0.3306196630001068, f1 0.3338182270526886\n",
            "Rouge-l: recall 0.5215343832969666, precision 0.44730716943740845, f1 0.45264753699302673\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 22/22 [02:46<00:00,  7.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "----ACC----\n",
            "Rouge-1: recall 0.5492520332336426, precision 0.46647870540618896, f1 0.47440892457962036\n",
            "Rouge-2: recall 0.4034233093261719, precision 0.3237416446208954, f1 0.32917407155036926\n",
            "Rouge-l: recall 0.5217207074165344, precision 0.4402707815170288, f1 0.44875916838645935\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O767bnuxlHrB"
      },
      "source": [
        "# baselines\n",
        "random_baseline(val_ds, vocab, batch_size, MAX_SENTENCES)\n",
        "random_baseline(test_ds, vocab, batch_size, MAX_SENTENCES)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}